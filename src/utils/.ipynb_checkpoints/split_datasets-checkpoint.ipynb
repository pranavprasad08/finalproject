{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ab467f-de3a-4c6f-8de5-c442eac30d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4085f7ae-0ab2-4b20-8f46-a82d8b9cfb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_coco_dataset(coco_json_path, output_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    # Load the original COCO dataset\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Extract the image IDs\n",
    "    image_ids = [img['id'] for img in coco_data['images']]\n",
    "    \n",
    "    # Perform the train-val-test split\n",
    "    train_ids, temp_ids = train_test_split(image_ids, test_size=(val_ratio + test_ratio), random_state=42)\n",
    "    val_ids, test_ids = train_test_split(temp_ids, test_size=(test_ratio / (val_ratio + test_ratio)), random_state=42)\n",
    "    \n",
    "    # Helper function to filter images and annotations\n",
    "    def filter_coco_data(image_ids, coco_data):\n",
    "        images = [img for img in coco_data['images'] if img['id'] in image_ids]\n",
    "        annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] in image_ids]\n",
    "        return {\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations,\n",
    "            \"categories\": coco_data['categories']\n",
    "        }\n",
    "    \n",
    "    # Create output directories if they don't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate the split datasets\n",
    "    train_data = filter_coco_data(train_ids, coco_data)\n",
    "    val_data = filter_coco_data(val_ids, coco_data)\n",
    "    test_data = filter_coco_data(test_ids, coco_data)\n",
    "    \n",
    "    # Save the split datasets\n",
    "    with open(os.path.join(output_dir, 'train_coco.json'), 'w') as f:\n",
    "        json.dump(train_data, f)\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'val_coco.json'), 'w') as f:\n",
    "        json.dump(val_data, f)\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'test_coco.json'), 'w') as f:\n",
    "        json.dump(test_data, f)\n",
    "    \n",
    "    print(\"Dataset split complete. Files saved in:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c18353-d441-434e-b427-b55d6f2eded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Files saved in: D:\\UoL\\Final Project\\src\\datasets\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "split_coco_dataset(r\"D:\\UoL\\Final Project\\src\\datasets\\updated_coco_dataset.json\", r\"D:\\UoL\\Final Project\\src\\datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7265bfa-09c8-4818-9e71-eec27b6b2f13",
   "metadata": {},
   "source": [
    "## Create COCO folder structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa0fc5b4-bcff-4d84-8a97-150aadb9eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coco_structure_with_renamed_images_and_filtered_annotations(coco_json_path, images_dir, output_dir):\n",
    "    # Load the COCO dataset\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create the required COCO directories\n",
    "    images_output_dir = os.path.join(output_dir, 'images')\n",
    "    \n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Lists to store the updated image info and valid annotations\n",
    "    updated_images = []\n",
    "    valid_annotations = []\n",
    "    \n",
    "    # Copy images to the output images directory and rename them using their ID\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        image_filename = image_info['file_name']\n",
    "        image_ext = os.path.splitext(image_filename)[1]  # Get the file extension\n",
    "        \n",
    "        # Construct the new filename using the image ID\n",
    "        new_image_filename = f\"{image_id}{image_ext}\"\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "        new_image_path = os.path.join(images_output_dir, new_image_filename)\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.copy(image_path, new_image_path)\n",
    "            image_info['file_name'] = new_image_filename  # Update the file name in the COCO data\n",
    "            updated_images.append(image_info)\n",
    "            \n",
    "            # Include annotations that belong to this image\n",
    "            image_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "            valid_annotations.extend(image_annotations)\n",
    "        else:\n",
    "            print(f\"Image {image_filename} not found. Skipping...\")\n",
    "    \n",
    "    # Update the images and annotations fields in the COCO data with valid entries\n",
    "    coco_data['images'] = updated_images\n",
    "    coco_data['annotations'] = valid_annotations\n",
    "    \n",
    "    # Save the updated COCO annotations file\n",
    "    annotations_filename = os.path.splitext(os.path.basename(coco_json_path))[0] + '.json'\n",
    "    annotations_output_path = os.path.join(output_dir, annotations_filename)\n",
    "    \n",
    "    with open(annotations_output_path, 'w') as f:\n",
    "        json.dump(coco_data, f)\n",
    "    \n",
    "    print(f\"COCO file structure with renamed images and filtered annotations generated:\")\n",
    "    print(f\"Images saved in: {images_output_dir}\")\n",
    "    print(f\"Updated annotations saved in: {annotations_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc13dc58-4f22-497b-a6ca-51e4ba525827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image images\\IOPA (22673).jpg not found. Skipping...\n",
      "Image images\\IOPA (3265).jpg not found. Skipping...\n",
      "Image images\\IOPA (22788).jpg not found. Skipping...\n",
      "Image IOP's/lopa_1_jpg_quality/IOPA (22038).jpg not found. Skipping...\n",
      "Image images\\IOPA (25830).jpg not found. Skipping...\n",
      "Image images\\year (2142).jpg not found. Skipping...\n",
      "Image images\\IOPA (7815).jpg not found. Skipping...\n",
      "Image images\\IOPA (27255).jpg not found. Skipping...\n",
      "Image images\\IOPA (20879).jpg not found. Skipping...\n",
      "Image images\\IOPA (21151).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/train/images\n",
      "Updated annotations saved in: datasets/coco/train/annotations\\train_coco.json\n",
      "Image images\\IOPA (24024).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/val/images\n",
      "Updated annotations saved in: datasets/coco/val/annotations\\val_coco.json\n",
      "Image images\\IOPA (9113).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/test/images\n",
      "Updated annotations saved in: datasets/coco/test/annotations\\test_coco.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "generate_coco_structure_with_renamed_images('datasets/train_coco.json', 'datasets', 'datasets/coco/train/')\n",
    "generate_coco_structure_with_renamed_images('datasets/val_coco.json', 'datasets', 'datasets/coco/val/')\n",
    "generate_coco_structure_with_renamed_images('datasets/test_coco.json', 'datasets', 'datasets/coco/test/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3bd9b-f208-4cbe-89ad-4242fa14fe87",
   "metadata": {},
   "source": [
    "## Create Yolo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7ed95d6-58d1-4d9e-bab0-d8ea9cecc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_segmentation_to_yolo(coco_json_path, images_dir, output_dir):\n",
    "    # Load the COCO dataset\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create output directories if they don't exist\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    images_output_dir = os.path.join(output_dir, 'images')\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a category ID to index map\n",
    "    category_id_to_index = {category['id']: idx for idx, category in enumerate(coco_data['categories'])}\n",
    "    \n",
    "    # Lists to keep track of valid images and annotations\n",
    "    valid_images = []\n",
    "    valid_annotations = []\n",
    "    \n",
    "    # Process each image\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "        image_filename = image_info['file_name']\n",
    "        \n",
    "        # Check if the image exists\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_filename} not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Copy image to the output images directory with the new ID-based filename\n",
    "        new_filename = f\"{image_id}\"\n",
    "        new_image_path = os.path.join(images_output_dir, f\"{new_filename}{os.path.splitext(image_filename)[1]}\")\n",
    "        shutil.copy(image_path, new_image_path)\n",
    "        \n",
    "        # Filter annotations for this image\n",
    "        annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "        \n",
    "        # YOLO format annotations\n",
    "        yolo_annotations = []\n",
    "        \n",
    "        for anno in annotations:\n",
    "            category_id = anno['category_id']\n",
    "            category_index = category_id_to_index[category_id]\n",
    "            \n",
    "            # Convert segmentation points to YOLO format\n",
    "            if 'segmentation' in anno:\n",
    "                segmentation = anno['segmentation']\n",
    "                \n",
    "                if type(segmentation) == list:  # Polygon segmentation\n",
    "                    for segment in segmentation:\n",
    "                        segment_str = ' '.join([f\"{(x / image_width):.6f} {(y / image_height):.6f}\" for x, y in zip(segment[::2], segment[1::2])])\n",
    "                        yolo_annotations.append(f\"{category_index} {segment_str}\")\n",
    "        \n",
    "        # Write the YOLO annotation file using the image ID as the filename\n",
    "        if yolo_annotations:\n",
    "            yolo_filename = os.path.join(labels_dir, f\"{new_filename}.txt\")\n",
    "            with open(yolo_filename, 'w') as yolo_file:\n",
    "                yolo_file.write(\"\\n\".join(yolo_annotations))\n",
    "            \n",
    "            # Add valid images and annotations\n",
    "            valid_images.append(image_info)\n",
    "            valid_annotations.extend(annotations)\n",
    "    \n",
    "    # Save the filtered COCO dataset (optional)\n",
    "    filtered_coco_data = {\n",
    "        \"images\": valid_images,\n",
    "        \"annotations\": valid_annotations,\n",
    "        \"categories\": coco_data['categories']\n",
    "    }\n",
    "    \n",
    "    filtered_coco_path = os.path.join(output_dir, 'filtered_coco_dataset.json')\n",
    "    with open(filtered_coco_path, 'w') as f:\n",
    "        json.dump(filtered_coco_data, f)\n",
    "    \n",
    "    print(f\"YOLO segmentation format annotations saved in: {labels_dir}\")\n",
    "    print(f\"Images copied to: {images_output_dir}\")\n",
    "    print(f\"Filtered COCO dataset saved as: {filtered_coco_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb06c46-7777-4901-94d4-674765bde701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image images\\IOPA (22673).jpg not found. Skipping...\n",
      "Image images\\IOPA (3265).jpg not found. Skipping...\n",
      "Image images\\IOPA (22788).jpg not found. Skipping...\n",
      "Image IOP's/lopa_1_jpg_quality/IOPA (22038).jpg not found. Skipping...\n",
      "Image images\\IOPA (25830).jpg not found. Skipping...\n",
      "Image images\\year (2142).jpg not found. Skipping...\n",
      "Image images\\IOPA (7815).jpg not found. Skipping...\n",
      "Image images\\IOPA (27255).jpg not found. Skipping...\n",
      "Image images\\IOPA (20879).jpg not found. Skipping...\n",
      "Image images\\IOPA (21151).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datasets/yolo/train/labels\n",
      "Images copied to: datasets/yolo/train/images\n",
      "Filtered COCO dataset saved as: datasets/yolo/train/filtered_coco_dataset.json\n",
      "Image images\\IOPA (24024).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datasets/yolo/val/labels\n",
      "Images copied to: datasets/yolo/val/images\n",
      "Filtered COCO dataset saved as: datasets/yolo/val/filtered_coco_dataset.json\n",
      "Image images\\IOPA (9113).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datsets/yolo/test/labels\n",
      "Images copied to: datsets/yolo/test/images\n",
      "Filtered COCO dataset saved as: datsets/yolo/test/filtered_coco_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "coco_segmentation_to_yolo('datasets/train_coco.json', 'datasets', 'datasets/yolo/train/')\n",
    "coco_segmentation_to_yolo('datasets/val_coco.json', 'datasets', 'datasets/yolo/val/')\n",
    "coco_segmentation_to_yolo('datasets/test_coco.json', 'datasets', 'datasets/yolo/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b5c25-e93d-4f0b-ad32-4afe142651a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
