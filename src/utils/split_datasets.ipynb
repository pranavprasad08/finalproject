{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ab467f-de3a-4c6f-8de5-c442eac30d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298abed5-3687-4715-a19c-29b604839151",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_json = r\"D:\\UoL\\Final Project\\src\\datasets\\updated_coco_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4085f7ae-0ab2-4b20-8f46-a82d8b9cfb4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m image_labels \u001b[38;5;241m=\u001b[39m mlb\u001b[38;5;241m.\u001b[39mfit_transform([\u001b[38;5;28mlist\u001b[39m(filtered_image_categories[img_id]) \u001b[38;5;28;01mfor\u001b[39;00m img_id \u001b[38;5;129;01min\u001b[39;00m valid_image_ids])\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Split the dataset into train and temp (test + val)\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m train_ids, temp_ids, train_labels, temp_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_image_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[0;32m     51\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Further split the temp set into validation and test sets\u001b[39;00m\n\u001b[0;32m     54\u001b[0m val_ids, test_ids, val_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     55\u001b[0m     temp_ids, temp_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, stratify\u001b[38;5;241m=\u001b[39mtemp_labels, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\finalproject\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\finalproject\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2801\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2797\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2799\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2808\u001b[0m     )\n\u001b[0;32m   2809\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\finalproject\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1843\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1814\u001b[0m \n\u001b[0;32m   1815\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1843\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\finalproject\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2247\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2245\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2252\u001b[0m     )\n\u001b[0;32m   2254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2255\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2258\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "# Load the COCO dataset as a JSON object\n",
    "with open(coco_json, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Extract images and annotations\n",
    "images = coco_data['images']\n",
    "annotations = coco_data['annotations']\n",
    "categories = coco_data['categories']\n",
    "\n",
    "# Create a dictionary to store the categories for each image\n",
    "image_categories = {}\n",
    "\n",
    "for ann in annotations:\n",
    "    img_id = ann['image_id']\n",
    "    cat_id = ann['category_id']\n",
    "    if img_id not in image_categories:\n",
    "        image_categories[img_id] = set()\n",
    "    image_categories[img_id].add(cat_id)\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = Counter([ann['category_id'] for ann in annotations])\n",
    "\n",
    "# Set a minimum threshold for the number of samples per class\n",
    "min_samples = 2\n",
    "\n",
    "# Filter out all classes that do not meet the minimum threshold\n",
    "common_classes = {cat_id for cat_id, count in class_counts.items() if count >= min_samples}\n",
    "\n",
    "# Filter images that contain only common classes\n",
    "filtered_image_categories = {img_id: cats.intersection(common_classes) for img_id, cats in image_categories.items()}\n",
    "filtered_image_categories = {img_id: cats for img_id, cats in filtered_image_categories.items() if cats}\n",
    "\n",
    "# Remove images with classes that have fewer than 2 occurrences\n",
    "valid_image_ids = []\n",
    "for img_id, cats in filtered_image_categories.items():\n",
    "    if all(class_counts[cat_id] >= min_samples for cat_id in cats):\n",
    "        valid_image_ids.append(img_id)\n",
    "\n",
    "# Convert the filtered image categories to a binary matrix\n",
    "image_labels = mlb.fit_transform([list(filtered_image_categories[img_id]) for img_id in valid_image_ids])\n",
    "\n",
    "# Split the dataset into train and temp (test + val)\n",
    "train_ids, temp_ids, train_labels, temp_labels = train_test_split(\n",
    "    valid_image_ids, image_labels, test_size=0.3, stratify=image_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Further split the temp set into validation and test sets\n",
    "val_ids, test_ids, val_labels, test_labels = train_test_split(\n",
    "    temp_ids, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "def save_coco_annotations(coco_data, img_ids, output_file):\n",
    "    # Filter images\n",
    "    filtered_images = [img for img in coco_data['images'] if img['id'] in img_ids]\n",
    "    \n",
    "    # Filter annotations\n",
    "    filtered_annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] in img_ids]\n",
    "    \n",
    "    # Create a new COCO formatted dictionary\n",
    "    coco_split = {\n",
    "        'images': filtered_images,\n",
    "        'annotations': filtered_annotations,\n",
    "        'categories': [cat for cat in coco_data['categories'] if cat['id'] in common_classes]\n",
    "    }\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(coco_split, f)\n",
    "\n",
    "# Save the splits\n",
    "save_coco_annotations(coco_data, train_ids, 'coco_train.json')\n",
    "save_coco_annotations(coco_data, val_ids, 'coco_val.json')\n",
    "save_coco_annotations(coco_data, test_ids, 'coco_test.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c18353-d441-434e-b427-b55d6f2eded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete. Files saved in: D:\\UoL\\Final Project\\src\\datasets\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "split_coco_dataset(r\"D:\\UoL\\Final Project\\src\\datasets\\updated_coco_dataset.json\", r\"D:\\UoL\\Final Project\\src\\datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7265bfa-09c8-4818-9e71-eec27b6b2f13",
   "metadata": {},
   "source": [
    "## Create COCO folder structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa0fc5b4-bcff-4d84-8a97-150aadb9eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coco_structure_with_renamed_images_and_filtered_annotations(coco_json_path, images_dir, output_dir):\n",
    "    # Load the COCO dataset\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create the required COCO directories\n",
    "    images_output_dir = os.path.join(output_dir, 'images')\n",
    "    \n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Lists to store the updated image info and valid annotations\n",
    "    updated_images = []\n",
    "    valid_annotations = []\n",
    "    \n",
    "    # Copy images to the output images directory and rename them using their ID\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        image_filename = image_info['file_name']\n",
    "        image_ext = os.path.splitext(image_filename)[1]  # Get the file extension\n",
    "        \n",
    "        # Construct the new filename using the image ID\n",
    "        new_image_filename = f\"{image_id}{image_ext}\"\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "        new_image_path = os.path.join(images_output_dir, new_image_filename)\n",
    "        \n",
    "        # Check if the image exists\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.copy(image_path, new_image_path)\n",
    "            image_info['file_name'] = new_image_filename  # Update the file name in the COCO data\n",
    "            updated_images.append(image_info)\n",
    "            \n",
    "            # Include annotations that belong to this image\n",
    "            image_annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "            valid_annotations.extend(image_annotations)\n",
    "        else:\n",
    "            print(f\"Image {image_filename} not found. Skipping...\")\n",
    "    \n",
    "    # Update the images and annotations fields in the COCO data with valid entries\n",
    "    coco_data['images'] = updated_images\n",
    "    coco_data['annotations'] = valid_annotations\n",
    "    \n",
    "    # Save the updated COCO annotations file\n",
    "    annotations_filename = os.path.splitext(os.path.basename(coco_json_path))[0] + '.json'\n",
    "    annotations_output_path = os.path.join(output_dir, annotations_filename)\n",
    "    \n",
    "    with open(annotations_output_path, 'w') as f:\n",
    "        json.dump(coco_data, f)\n",
    "    \n",
    "    print(f\"COCO file structure with renamed images and filtered annotations generated:\")\n",
    "    print(f\"Images saved in: {images_output_dir}\")\n",
    "    print(f\"Updated annotations saved in: {annotations_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc13dc58-4f22-497b-a6ca-51e4ba525827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image images\\IOPA (22673).jpg not found. Skipping...\n",
      "Image images\\IOPA (3265).jpg not found. Skipping...\n",
      "Image images\\IOPA (22788).jpg not found. Skipping...\n",
      "Image IOP's/lopa_1_jpg_quality/IOPA (22038).jpg not found. Skipping...\n",
      "Image images\\IOPA (25830).jpg not found. Skipping...\n",
      "Image images\\year (2142).jpg not found. Skipping...\n",
      "Image images\\IOPA (7815).jpg not found. Skipping...\n",
      "Image images\\IOPA (27255).jpg not found. Skipping...\n",
      "Image images\\IOPA (20879).jpg not found. Skipping...\n",
      "Image images\\IOPA (21151).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/train/images\n",
      "Updated annotations saved in: datasets/coco/train/annotations\\train_coco.json\n",
      "Image images\\IOPA (24024).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/val/images\n",
      "Updated annotations saved in: datasets/coco/val/annotations\\val_coco.json\n",
      "Image images\\IOPA (9113).jpg not found. Skipping...\n",
      "COCO file structure with renamed images generated:\n",
      "Images saved in: datasets/coco/test/images\n",
      "Updated annotations saved in: datasets/coco/test/annotations\\test_coco.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "generate_coco_structure_with_renamed_images('datasets/train_coco.json', 'datasets', 'datasets/coco/train/')\n",
    "generate_coco_structure_with_renamed_images('datasets/val_coco.json', 'datasets', 'datasets/coco/val/')\n",
    "generate_coco_structure_with_renamed_images('datasets/test_coco.json', 'datasets', 'datasets/coco/test/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3bd9b-f208-4cbe-89ad-4242fa14fe87",
   "metadata": {},
   "source": [
    "## Create Yolo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7ed95d6-58d1-4d9e-bab0-d8ea9cecc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_segmentation_to_yolo(coco_json_path, images_dir, output_dir):\n",
    "    # Load the COCO dataset\n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Create output directories if they don't exist\n",
    "    labels_dir = os.path.join(output_dir, 'labels')\n",
    "    images_output_dir = os.path.join(output_dir, 'images')\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a category ID to index map\n",
    "    category_id_to_index = {category['id']: idx for idx, category in enumerate(coco_data['categories'])}\n",
    "    \n",
    "    # Lists to keep track of valid images and annotations\n",
    "    valid_images = []\n",
    "    valid_annotations = []\n",
    "    \n",
    "    # Process each image\n",
    "    for image_info in coco_data['images']:\n",
    "        image_id = image_info['id']\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "        image_filename = image_info['file_name']\n",
    "        \n",
    "        # Check if the image exists\n",
    "        image_path = os.path.join(images_dir, image_filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_filename} not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Copy image to the output images directory with the new ID-based filename\n",
    "        new_filename = f\"{image_id}\"\n",
    "        new_image_path = os.path.join(images_output_dir, f\"{new_filename}{os.path.splitext(image_filename)[1]}\")\n",
    "        shutil.copy(image_path, new_image_path)\n",
    "        \n",
    "        # Filter annotations for this image\n",
    "        annotations = [anno for anno in coco_data['annotations'] if anno['image_id'] == image_id]\n",
    "        \n",
    "        # YOLO format annotations\n",
    "        yolo_annotations = []\n",
    "        \n",
    "        for anno in annotations:\n",
    "            category_id = anno['category_id']\n",
    "            category_index = category_id_to_index[category_id]\n",
    "            \n",
    "            # Convert segmentation points to YOLO format\n",
    "            if 'segmentation' in anno:\n",
    "                segmentation = anno['segmentation']\n",
    "                \n",
    "                if type(segmentation) == list:  # Polygon segmentation\n",
    "                    for segment in segmentation:\n",
    "                        segment_str = ' '.join([f\"{(x / image_width):.6f} {(y / image_height):.6f}\" for x, y in zip(segment[::2], segment[1::2])])\n",
    "                        yolo_annotations.append(f\"{category_index} {segment_str}\")\n",
    "        \n",
    "        # Write the YOLO annotation file using the image ID as the filename\n",
    "        if yolo_annotations:\n",
    "            yolo_filename = os.path.join(labels_dir, f\"{new_filename}.txt\")\n",
    "            with open(yolo_filename, 'w') as yolo_file:\n",
    "                yolo_file.write(\"\\n\".join(yolo_annotations))\n",
    "            \n",
    "            # Add valid images and annotations\n",
    "            valid_images.append(image_info)\n",
    "            valid_annotations.extend(annotations)\n",
    "    \n",
    "    # Save the filtered COCO dataset (optional)\n",
    "    filtered_coco_data = {\n",
    "        \"images\": valid_images,\n",
    "        \"annotations\": valid_annotations,\n",
    "        \"categories\": coco_data['categories']\n",
    "    }\n",
    "    \n",
    "    filtered_coco_path = os.path.join(output_dir, 'filtered_coco_dataset.json')\n",
    "    with open(filtered_coco_path, 'w') as f:\n",
    "        json.dump(filtered_coco_data, f)\n",
    "    \n",
    "    print(f\"YOLO segmentation format annotations saved in: {labels_dir}\")\n",
    "    print(f\"Images copied to: {images_output_dir}\")\n",
    "    print(f\"Filtered COCO dataset saved as: {filtered_coco_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cb06c46-7777-4901-94d4-674765bde701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image images\\IOPA (22673).jpg not found. Skipping...\n",
      "Image images\\IOPA (3265).jpg not found. Skipping...\n",
      "Image images\\IOPA (22788).jpg not found. Skipping...\n",
      "Image IOP's/lopa_1_jpg_quality/IOPA (22038).jpg not found. Skipping...\n",
      "Image images\\IOPA (25830).jpg not found. Skipping...\n",
      "Image images\\year (2142).jpg not found. Skipping...\n",
      "Image images\\IOPA (7815).jpg not found. Skipping...\n",
      "Image images\\IOPA (27255).jpg not found. Skipping...\n",
      "Image images\\IOPA (20879).jpg not found. Skipping...\n",
      "Image images\\IOPA (21151).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datasets/yolo/train/labels\n",
      "Images copied to: datasets/yolo/train/images\n",
      "Filtered COCO dataset saved as: datasets/yolo/train/filtered_coco_dataset.json\n",
      "Image images\\IOPA (24024).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datasets/yolo/val/labels\n",
      "Images copied to: datasets/yolo/val/images\n",
      "Filtered COCO dataset saved as: datasets/yolo/val/filtered_coco_dataset.json\n",
      "Image images\\IOPA (9113).jpg not found. Skipping...\n",
      "YOLO segmentation format annotations saved in: datsets/yolo/test/labels\n",
      "Images copied to: datsets/yolo/test/images\n",
      "Filtered COCO dataset saved as: datsets/yolo/test/filtered_coco_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "coco_segmentation_to_yolo('datasets/train_coco.json', 'datasets', 'datasets/yolo/train/')\n",
    "coco_segmentation_to_yolo('datasets/val_coco.json', 'datasets', 'datasets/yolo/val/')\n",
    "coco_segmentation_to_yolo('datasets/test_coco.json', 'datasets', 'datasets/yolo/test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239b5c25-e93d-4f0b-ad32-4afe142651a1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
