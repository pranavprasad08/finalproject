{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c5e2bc-c5cc-49df-a5d1-0ff2e49c33b7",
   "metadata": {},
   "source": [
    "First we can download the masks locally and rename the uri in the database, to do that we need to connect to Labelbox with an api key and then download the masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a43cfda-2f8a-4890-85ce-9d8574df0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from labelbox import Client\n",
    "import urllib.request\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a0c4dc-37c7-4ddb-9890-f9ffc236c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the directory where you want to save the masks\n",
    "local_mask_dir = 'masks/'\n",
    "os.makedirs(local_mask_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3110638-a9c2-42e8-979f-44949135753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja3FzZzBqbTZjaXNnMHlibzl1bmg5N2p3Iiwib3JnYW5pemF0aW9uSWQiOiJja3FzZzBqbHljaXNmMHlibzA2cmw3aWs0IiwiYXBpS2V5SWQiOiJjbHpya2gxbmIwOGxxMDd5cWJmZmk1YnoxIiwic2VjcmV0IjoiNGI3MWE4MTJiZDdjYzE1MmM4YzlkM2FhMmQxZGIzNDQiLCJpYXQiOjE3MjM1MDE4MDIsImV4cCI6MjM1NDY1MzgwMn0.iZyDJoC3UQY1s6L06pnnix9Ac4ssvk8mb_NurwHKwts'\n",
    "client = Client(api_key)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c17cbb0-3d17-48d3-a45c-8b95667dc453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your database\n",
    "conn = sqlite3.connect('dataset.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6eeaf3a-f3a4-46fd-8049-4d6dd413058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch all segmentation annotations\n",
    "cursor.execute(\"SELECT id, value FROM annotations WHERE type='segmentation'\")\n",
    "annotations = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bc3ec6-4ba1-49ba-9ebf-5d841658bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each annotation\n",
    "def process_annotation(annotation):\n",
    "    annotation_id, mask_url = annotation\n",
    "    file_name = annotation_id + '.png'\n",
    "    \n",
    "    if os.path.isfile(os.path.join(local_mask_dir, file_name)):\n",
    "        print('in folder')\n",
    "        return (None, None)  # Skip if file exists\n",
    "\n",
    "    try:\n",
    "        # Determine the local file path\n",
    "        local_filename = os.path.join(local_mask_dir, file_name)\n",
    "        \n",
    "        # Download the mask using urllib.request\n",
    "        req = urllib.request.Request(mask_url, headers=headers)\n",
    "        image = Image.open(urllib.request.urlopen(req))\n",
    "        image.save(local_filename)\n",
    "        \n",
    "        print(f\"Downloaded: {annotation_id}\")\n",
    "        return (annotation_id, local_filename)  # Return the update information\n",
    "    \n",
    "    except urllib.error.HTTPError as e:\n",
    "        print(f\"HTTP error occurred: {e}\")\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"URL error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process annotation {annotation_id}: {e}\")\n",
    "    \n",
    "    return (None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ccc8c1-72b5-4d47-8687-66605fbfcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for annotation_id, mask_url in annotations:\n",
    "#     #took a long time so ran multiple times so i needed to check if the file already existed\n",
    "#     file_name = annotation_id + '.png'\n",
    "#     if os.path.isfile(os.path.join(local_mask_dir, file_name)):\n",
    "#         print('in folder')\n",
    "#     else:\n",
    "#         try:\n",
    "#             # Determine the local file path\n",
    "#             local_filename = os.path.join(local_mask_dir, f\"{annotation_id}.png\")\n",
    "                \n",
    "#             # Download the mask using urllib.request\n",
    "#             req = urllib.request.Request(mask_url, headers=headers)\n",
    "#             image = Image.open(urllib.request.urlopen(req))\n",
    "#             image.save(local_filename)\n",
    "            \n",
    "#             # Update the database with the local file path\n",
    "#             cursor.execute(\"UPDATE annotations SET value = ? WHERE id = ?\", (local_filename, annotation_id))\n",
    "#             print(f\"Downloaded and updated: {annotation_id}\")\n",
    "        \n",
    "#         except urllib.error.HTTPError as e:\n",
    "#             print(f\"HTTP error occurred: {e}\")\n",
    "#         except urllib.error.URLError as e:\n",
    "#             print(f\"URL error occurred: {e}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to process annotation {annotation_id}: {e}\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07b355d-837a-4905-b682-82dc6753abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to collect updates\n",
    "updates = []     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb992f2-fb4e-4e02-847f-f8c74e322ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using ThreadPoolExecutor for parallel processing\n",
    "# with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "#     results = executor.map(process_annotation, annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614514b2-7691-42e0-a565-0086792db706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the updates\n",
    "updates = [(annotation_id, local_filename) for annotation_id, local_filename in results if annotation_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d651a6f-6a10-40da-9ced-5e524b30d89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database updated with 209 records.\n"
     ]
    }
   ],
   "source": [
    "# Perform the database update in a single transaction\n",
    "if updates:\n",
    "    cursor.executemany(\"UPDATE annotations SET value = ? WHERE id = ?\", updates)\n",
    "    print(f\"Database updated with {len(updates)} records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "471453f0-f9f5-42f3-8d8f-020cac08f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All masks downloaded and database updated.\n"
     ]
    }
   ],
   "source": [
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"All masks downloaded and database updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5fba155-3765-41c9-8060-d75280e17deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows with 'segmentation' type: 137653\n",
      "Processed 1000 of 137653 rows\n",
      "Processed 2000 of 137653 rows\n",
      "Processed 3000 of 137653 rows\n",
      "Processed 4000 of 137653 rows\n",
      "Processed 5000 of 137653 rows\n",
      "Processed 6000 of 137653 rows\n",
      "Processed 7000 of 137653 rows\n",
      "Processed 8000 of 137653 rows\n",
      "Processed 9000 of 137653 rows\n",
      "Processed 10000 of 137653 rows\n",
      "Processed 11000 of 137653 rows\n",
      "Processed 12000 of 137653 rows\n",
      "Processed 13000 of 137653 rows\n",
      "Processed 14000 of 137653 rows\n",
      "Processed 15000 of 137653 rows\n",
      "Processed 16000 of 137653 rows\n",
      "Processed 17000 of 137653 rows\n",
      "Processed 18000 of 137653 rows\n",
      "Processed 19000 of 137653 rows\n",
      "Processed 20000 of 137653 rows\n",
      "Processed 21000 of 137653 rows\n",
      "Processed 22000 of 137653 rows\n",
      "Processed 23000 of 137653 rows\n",
      "Processed 24000 of 137653 rows\n",
      "Processed 25000 of 137653 rows\n",
      "Processed 26000 of 137653 rows\n",
      "Processed 27000 of 137653 rows\n",
      "Processed 28000 of 137653 rows\n",
      "Processed 29000 of 137653 rows\n",
      "Processed 30000 of 137653 rows\n",
      "Processed 31000 of 137653 rows\n",
      "Processed 32000 of 137653 rows\n",
      "Processed 33000 of 137653 rows\n",
      "Processed 34000 of 137653 rows\n",
      "Processed 35000 of 137653 rows\n",
      "Processed 36000 of 137653 rows\n",
      "Processed 37000 of 137653 rows\n",
      "Processed 38000 of 137653 rows\n",
      "Processed 39000 of 137653 rows\n",
      "Processed 40000 of 137653 rows\n",
      "Processed 41000 of 137653 rows\n",
      "Processed 42000 of 137653 rows\n",
      "Processed 43000 of 137653 rows\n",
      "Processed 44000 of 137653 rows\n",
      "Processed 45000 of 137653 rows\n",
      "Processed 46000 of 137653 rows\n",
      "Processed 47000 of 137653 rows\n",
      "Processed 48000 of 137653 rows\n",
      "Processed 49000 of 137653 rows\n",
      "Processed 50000 of 137653 rows\n",
      "Processed 51000 of 137653 rows\n",
      "Processed 52000 of 137653 rows\n",
      "Processed 53000 of 137653 rows\n",
      "Processed 54000 of 137653 rows\n",
      "Processed 55000 of 137653 rows\n",
      "Processed 56000 of 137653 rows\n",
      "Processed 57000 of 137653 rows\n",
      "Processed 58000 of 137653 rows\n",
      "Processed 59000 of 137653 rows\n",
      "Processed 60000 of 137653 rows\n",
      "Processed 61000 of 137653 rows\n",
      "Processed 62000 of 137653 rows\n",
      "Processed 63000 of 137653 rows\n",
      "Processed 64000 of 137653 rows\n",
      "Processed 65000 of 137653 rows\n",
      "Processed 66000 of 137653 rows\n",
      "Processed 67000 of 137653 rows\n",
      "Processed 68000 of 137653 rows\n",
      "Processed 69000 of 137653 rows\n",
      "Processed 70000 of 137653 rows\n",
      "Processed 71000 of 137653 rows\n",
      "Processed 72000 of 137653 rows\n",
      "Processed 73000 of 137653 rows\n",
      "Processed 74000 of 137653 rows\n",
      "Processed 75000 of 137653 rows\n",
      "Processed 76000 of 137653 rows\n",
      "Processed 77000 of 137653 rows\n",
      "Processed 78000 of 137653 rows\n",
      "Processed 79000 of 137653 rows\n",
      "Processed 80000 of 137653 rows\n",
      "Processed 81000 of 137653 rows\n",
      "Processed 82000 of 137653 rows\n",
      "Processed 83000 of 137653 rows\n",
      "Processed 84000 of 137653 rows\n",
      "Processed 85000 of 137653 rows\n",
      "Processed 86000 of 137653 rows\n",
      "Processed 87000 of 137653 rows\n",
      "Processed 88000 of 137653 rows\n",
      "Processed 89000 of 137653 rows\n",
      "Processed 90000 of 137653 rows\n",
      "Processed 91000 of 137653 rows\n",
      "Processed 92000 of 137653 rows\n",
      "Processed 93000 of 137653 rows\n",
      "Processed 94000 of 137653 rows\n",
      "Processed 95000 of 137653 rows\n",
      "Processed 96000 of 137653 rows\n",
      "Processed 97000 of 137653 rows\n",
      "Processed 98000 of 137653 rows\n",
      "Processed 99000 of 137653 rows\n",
      "Processed 100000 of 137653 rows\n",
      "Processed 101000 of 137653 rows\n",
      "Processed 102000 of 137653 rows\n",
      "Processed 103000 of 137653 rows\n",
      "Processed 104000 of 137653 rows\n",
      "Processed 105000 of 137653 rows\n",
      "Processed 106000 of 137653 rows\n",
      "Processed 107000 of 137653 rows\n",
      "Processed 108000 of 137653 rows\n",
      "Processed 109000 of 137653 rows\n",
      "Processed 110000 of 137653 rows\n",
      "Processed 111000 of 137653 rows\n",
      "Processed 112000 of 137653 rows\n",
      "Processed 113000 of 137653 rows\n",
      "Processed 114000 of 137653 rows\n",
      "Processed 115000 of 137653 rows\n",
      "Processed 116000 of 137653 rows\n",
      "Processed 117000 of 137653 rows\n",
      "Processed 118000 of 137653 rows\n",
      "Processed 119000 of 137653 rows\n",
      "Processed 120000 of 137653 rows\n",
      "Processed 121000 of 137653 rows\n",
      "Processed 122000 of 137653 rows\n",
      "Processed 123000 of 137653 rows\n",
      "Processed 124000 of 137653 rows\n",
      "Processed 125000 of 137653 rows\n",
      "Processed 126000 of 137653 rows\n",
      "Processed 127000 of 137653 rows\n",
      "Processed 128000 of 137653 rows\n",
      "Processed 129000 of 137653 rows\n",
      "Processed 130000 of 137653 rows\n",
      "Processed 131000 of 137653 rows\n",
      "Processed 132000 of 137653 rows\n",
      "Processed 133000 of 137653 rows\n",
      "Processed 134000 of 137653 rows\n",
      "Processed 135000 of 137653 rows\n",
      "Processed 136000 of 137653 rows\n",
      "Processed 137000 of 137653 rows\n",
      "Database updated with 137653 records.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect('dataset.db')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Optimize the database for bulk updates\n",
    "cursor.execute(\"PRAGMA synchronous = OFF\")\n",
    "cursor.execute(\"PRAGMA journal_mode = WAL\")\n",
    "cursor.execute(\"PRAGMA foreign_keys = OFF\")\n",
    "cursor.execute(\"PRAGMA mmap_size = 30000000000\")  # 30 GB, adjust based on your system's memory\n",
    "\n",
    "# Fetch all rows with 'segmentation' type\n",
    "cursor.execute(\"SELECT id, value FROM annotations WHERE type = 'segmentation'\")\n",
    "segmentation_rows = cursor.fetchall()\n",
    "\n",
    "total_rows = len(segmentation_rows)\n",
    "print(f\"Total rows with 'segmentation' type: {total_rows}\")\n",
    "\n",
    "# Start a single large transaction\n",
    "cursor.execute(\"BEGIN TRANSACTION\")\n",
    "\n",
    "# Perform updates\n",
    "for index, (annotation_id, current_value) in enumerate(segmentation_rows, start=1):\n",
    "    new_value = f\"{annotation_id}.png\"\n",
    "    cursor.execute(\"UPDATE annotations SET value = ? WHERE id = ?\", (new_value, annotation_id))\n",
    "    \n",
    "    # Optionally, print progress every 1000 rows\n",
    "    if index % 1000 == 0:\n",
    "        print(f\"Processed {index} of {total_rows} rows\")\n",
    "\n",
    "# Commit the transaction\n",
    "connection.commit()\n",
    "print(f\"Database updated with {total_rows} records.\")\n",
    "\n",
    "# Restore settings after the update\n",
    "cursor.execute(\"PRAGMA synchronous = FULL\")\n",
    "cursor.execute(\"PRAGMA journal_mode = DELETE\")\n",
    "cursor.execute(\"PRAGMA foreign_keys = ON\")\n",
    "\n",
    "# Close the database connection\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b2e33ab-e689-42b8-acef-2d974a27701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to the SQLite database\n",
    "connection = sqlite3.connect('dataset.db')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT id, name, value FROM annotations WHERE type = 'segmentation'\")\n",
    "segmentation_rows = cursor.fetchall()\n",
    "for index, (annotation_id, name, current_value) in enumerate(segmentation_rows, start=1):\n",
    "   if os.path.isfile(os.path.join(local_mask_dir, current_value)):\n",
    "\n",
    "       continue \n",
    "\n",
    "   else:\n",
    "       print('not in folder')\n",
    "    \n",
    "\n",
    "# Close the database connection\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e157d4c-b612-421a-be9b-33a257a6b4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
