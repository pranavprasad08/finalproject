{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2861444e-3266-4437-8c9b-1cab4c853b4e",
   "metadata": {},
   "source": [
    "### COCO Dataset Format\n",
    "\n",
    "The COCO (Common Objects in Context) dataset format is widely used for object detection, segmentation, and keypoint detection tasks. The dataset is stored in a JSON file with the following key components:\n",
    "\n",
    "1. **Images**:\n",
    "    - Contains metadata for each image, such as:\n",
    "      - `id`: A unique identifier for the image.\n",
    "      - `file_name`: The name of the image file.\n",
    "      - `height`: The height of the image in pixels.\n",
    "      - `width`: The width of the image in pixels.\n",
    "\n",
    "2. **Annotations**:\n",
    "    - Contains annotations for objects within each image, such as:\n",
    "      - `id`: A unique identifier for the annotation.\n",
    "      - `image_id`: The ID of the image to which this annotation belongs.\n",
    "      - `category_id`: The ID of the category this object belongs to.\n",
    "      - `bbox`: (Optional) The bounding box of the object `[x, y, width, height]`.\n",
    "      - `segmentation`: (Optional) The segmentation mask for the object.\n",
    "      - `area`: (Optional) The area of the object in pixels.\n",
    "      - `iscrowd`: Indicates whether the annotation represents a crowd (1) or a single object (0).\n",
    "\n",
    "3. **Categories**:\n",
    "    - Contains a list of categories for classification, including:\n",
    "      - `id`: A unique identifier for the category.\n",
    "      - `name`: The name of the category (e.g., \"cat\", \"dog\").\n",
    "\n",
    "This format is designed to facilitate various computer vision tasks by organizing images, annotations, and categories in a standardized way, making it easier to train and evaluate models on diverse datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026de0ca-257a-4157-a1f3-c5e19d17c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools import mask as maskUtils\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b4d3fd-26d6-447f-8854-75a48f1de4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your database\n",
    "conn = sqlite3.connect('dataset.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e70479eb-8bf8-4d19-a2de-1d6b73a68cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique class names from segmentation annotations\n",
    "cursor.execute(\"SELECT DISTINCT name FROM annotations WHERE type='segmentation'\")\n",
    "unique_class_names = cursor.fetchall()\n",
    "\n",
    "# Step 2: Create the `categories` table\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS categories (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        name TEXT UNIQUE NOT NULL\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Step 3: Insert unique class names into the `categories` table\n",
    "for class_name in unique_class_names:\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO categories (name) VALUES (?)\", (class_name[0],))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062d67fc-4061-4eea-ad2e-247af29f9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch images\n",
    "cursor.execute(\"SELECT id, filename, height, width FROM images\")\n",
    "images = []\n",
    "for row in cursor.fetchall():\n",
    "    images.append({\n",
    "        \"id\": row[0],\n",
    "        \"file_name\": row[1],\n",
    "        \"height\": row[2],\n",
    "        \"width\": row[3]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3f958c-3771-4b74-83e9-1fe2b3dd492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch categories\n",
    "cursor.execute(\"SELECT id, name FROM categories\")\n",
    "categories = []\n",
    "category_id_map = {}  # Map category name to ID for fast lookup\n",
    "for row in cursor.fetchall():\n",
    "    category_id_map[row[1]] = row[0] - 1\n",
    "    categories.append({\n",
    "        \"id\": row[0] - 1,\n",
    "        \"name\": row[1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2689d959-15b9-4339-a68c-84745298f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fetch annotations\n",
    "cursor.execute(\"SELECT id, name, value, imageID FROM annotations WHERE type='segmentation'\")\n",
    "annotations = []\n",
    "for row in cursor.fetchall():\n",
    "    annotation_id, class_name, mask_path, image_id = row\n",
    "    \n",
    "    # Get the corresponding category ID\n",
    "    category_id = category_id_map[class_name]\n",
    "    \n",
    "    # Fetch the image size from the database or any other source\n",
    "    cursor.execute(\"SELECT width, height FROM images WHERE id=?\", (image_id,))\n",
    "    image_width, image_height = cursor.fetchone()  # Assuming the size is stored in the 'images' table\n",
    "\n",
    "    # Open the mask image and resize it to match the image size\n",
    "    with Image.open('datasets/masks/' + mask_path) as mask:\n",
    "        mask = mask.convert(\"L\")  # Ensure it's a grayscale image\n",
    "        original_size = mask.size  # Save the original size for reference if needed\n",
    "        mask = mask.resize((image_width, image_height), Image.NEAREST)  # Resize the mask to match the image size\n",
    "\n",
    "        mask_array = np.array(mask)\n",
    "        binary_mask = mask_array > 0  # Convert to binary mask\n",
    "\n",
    "        # Find contours (external contours only)\n",
    "        contours, _ = cv2.findContours(binary_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Convert contours to COCO format (list of lists)\n",
    "        segmentation = []\n",
    "        for contour in contours:\n",
    "            contour = contour.flatten().tolist()  # Flatten the contour array\n",
    "            if len(contour) > 4:  # Valid polygon must have at least 3 points (6 coordinates)\n",
    "                segmentation.append(contour)\n",
    "        \n",
    "        # Calculate the area using the binary mask\n",
    "        area = np.sum(binary_mask)\n",
    "        \n",
    "        # Calculate the bounding box\n",
    "        x, y, w, h = cv2.boundingRect(binary_mask.astype(np.uint8))\n",
    "        bbox = [x, y, w, h]\n",
    "\n",
    "    # Add the annotation to the list\n",
    "    annotations.append({\n",
    "        \"id\": annotation_id,\n",
    "        \"image_id\": image_id,\n",
    "        \"category_id\": category_id,\n",
    "        \"segmentation\": segmentation,  # List of polygon points\n",
    "        \"area\": int(area),\n",
    "        \"iscrowd\": 0,\n",
    "        \"bbox\": [[int(coord) for coord in bbox]],  # Convert to list of integers\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a1f4fa-a249-430d-9f73-a55f54faa76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Assemble the COCO dataset\n",
    "coco_dataset = {\n",
    "    \"images\": images,\n",
    "    \"annotations\": annotations,\n",
    "    \"categories\": categories\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e17fa27-081b-41ad-9495-7dfa6086a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#move images into one folder and update coco json\n",
    "def get_image_size(image_path):\n",
    "    with Image.open(image_path) as img:\n",
    "        return img.size\n",
    "\n",
    "def get_file_modification_time(file_path):\n",
    "    return os.path.getmtime(file_path)\n",
    "\n",
    "def process_image_file(file, root, images, seen_files, output_folder):\n",
    "    src_file_path = os.path.join(root, file)\n",
    "\n",
    "    for image in images:\n",
    "        json_file_name = os.path.basename(image['file_name'])\n",
    "        if json_file_name == file:\n",
    "            coco_width, coco_height = image['width'], image['height']\n",
    "            src_width, src_height = get_image_size(src_file_path)\n",
    "\n",
    "            if (src_width, src_height) == (coco_width, coco_height):\n",
    "                if file in seen_files:\n",
    "                    existing_file_path = seen_files[file]['path']\n",
    "                    if get_file_modification_time(src_file_path) > get_file_modification_time(existing_file_path):\n",
    "                        dst_file_path = os.path.join(output_folder, file)\n",
    "                        if os.path.exists(dst_file_path):\n",
    "                            os.remove(dst_file_path)\n",
    "                        shutil.copy2(src_file_path, dst_file_path)\n",
    "                        seen_files[file] = {'path': src_file_path, 'image_info': image}\n",
    "                        print(f\"Replaced {existing_file_path} with more recent {src_file_path}\")\n",
    "                    else:\n",
    "                        print(f\"Skipped {src_file_path} as {existing_file_path} is more recent\")\n",
    "                else:\n",
    "                    dst_file_path = os.path.join(output_folder, file)\n",
    "                    shutil.copy2(src_file_path, dst_file_path)\n",
    "                    seen_files[file] = {'path': src_file_path, 'image_info': image}\n",
    "                    print(f\"Copied {src_file_path} to {dst_file_path}\")\n",
    "            else:\n",
    "                print(f\"Skipped {src_file_path} due to size mismatch\")\n",
    "            break\n",
    "\n",
    "def combine_folders_and_update_coco(coco_dataset, input_folder, output_folder):\n",
    "    # Load the COCO dataset\n",
    "    coco_data = coco_dataset\n",
    "\n",
    "    images = coco_data['images']\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    seen_files = {}\n",
    "\n",
    "    # Using ThreadPoolExecutor for multithreading\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "        for root, _, files in os.walk(input_folder):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')):\n",
    "                    futures.append(executor.submit(process_image_file, file, root, images, seen_files, output_folder))\n",
    "\n",
    "        # Wait for all threads to complete\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as exc:\n",
    "                print(f\"Generated an exception: {exc}\")\n",
    "\n",
    "    # Update the file_name field in the COCO JSON\n",
    "    for image in images:\n",
    "        image_file_name = os.path.basename(image['file_name'])\n",
    "        if image_file_name in seen_files:\n",
    "            image['file_name'] = os.path.join('images', image_file_name)\n",
    "\n",
    "    # Save the updated COCO JSON file\n",
    "    coco_json_path = os.path.join(input_folder, 'coco_dataset.json')\n",
    "    with open(coco_json_path, 'w') as f:\n",
    "        json.dump(coco_data, f, indent=4)\n",
    "\n",
    "    print(f\"COCO dataset updated and saved to {coco_json_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# combine_folders_and_update_coco(\"path/to/coco.json\", \"path/to/input/folder\", \"path/to/output/folder\")\n",
    "\n",
    "\n",
    "             \n",
    "# Example usage\n",
    "output_dir = 'D:/UoL/Final Project/src/datasets/images'\n",
    "input_dir = 'D:/UoL/Final Project/src/datasets'\n",
    "combine_folders_and_update_coco(coco_dataset, input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25deaa6-ed76-468e-8208-eaed1f4a6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
